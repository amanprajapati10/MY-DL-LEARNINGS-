{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525baf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07abc962",
   "metadata": {},
   "source": [
    "Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad7406a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CGPA</th>\n",
       "      <th>PROFILE_SCORE</th>\n",
       "      <th>LPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CGPA  PROFILE_SCORE  LPA\n",
       "0     9              5    8\n",
       "1     9             11   10\n",
       "2     7              9    7\n",
       "3     8              6    7\n",
       "4     6              7    8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[9,5,8],[9,11,10],[7,9,7],[8,6,7],[6,7,8]],columns=['CGPA','PROFILE_SCORE','LPA'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07035f6c",
   "metadata": {},
   "source": [
    "Initializing all the weights and bias of all the layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3baf4ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(layer_dims):\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    for i in range(1,L):\n",
    "        parameters['W' + str(i)] = np.random.randn(layer_dims[i], layer_dims[i-1]) * 0.01\n",
    "        parameters['b' + str(i)] = np.zeros((layer_dims[i], 1))\n",
    "    return parameters   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c084f0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.01788628,  0.0043651 ],\n",
       "        [ 0.00096497, -0.01863493]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[-0.00277388, -0.00354759]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_weights_and_bias([2,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789787e6",
   "metadata": {},
   "source": [
    "Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5179116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    return Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba19bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_forward(X, parameters):  #Herer X is the input data and parameters are the weights and biases\n",
    "\n",
    "  A = X\n",
    "  L = len(parameters) // 2  # number of layers in the neural network\n",
    "  \n",
    "  for l in range(1, L+1):\n",
    "    A_prev = A \n",
    "    Wl = parameters['W' + str(l)]\n",
    "    bl = parameters['b' + str(l)]\n",
    "    A = linear_forward(A_prev, Wl, bl)\n",
    "    \n",
    "  return A,A_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6d425",
   "metadata": {},
   "source": [
    "Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32315fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, y, y_hat, A1, X):\n",
    "    learning_rate = 0.001\n",
    "    error = y - y_hat\n",
    "\n",
    "    # Update W2 (shape: 1 x 2)\n",
    "    parameters['W2'][0][0] += learning_rate * 2 * error * A1[0][0]\n",
    "    parameters['W2'][0][1] += learning_rate * 2 * error * A1[1][0]\n",
    "\n",
    "    # Update b2 (shape: 1 x 1)\n",
    "    parameters['b2'][0][0] += learning_rate * 2 * error\n",
    "\n",
    "    # Update W1 (shape: 2 x 2)\n",
    "    parameters['W1'][0][0] += learning_rate * 2 * error * parameters['W2'][0][0] * X[0][0]\n",
    "    parameters['W1'][0][1] += learning_rate * 2 * error * parameters['W2'][0][0] * X[1][0]\n",
    "    parameters['b1'][0][0] += learning_rate * 2 * error * parameters['W2'][0][0]\n",
    "\n",
    "    parameters['W1'][1][0] += learning_rate * 2 * error * parameters['W2'][0][1] * X[0][0]\n",
    "    parameters['W1'][1][1] += learning_rate * 2 * error * parameters['W2'][0][1] * X[1][0]\n",
    "    parameters['b1'][1][0] += learning_rate * 2 * error * parameters['W2'][0][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c459e55",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf017120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  1 Loss -  64.66008953273986\n",
      "Epoch -  2 Loss -  63.177588558236856\n",
      "Epoch -  3 Loss -  60.75346337590297\n",
      "Epoch -  4 Loss -  53.630082455732484\n",
      "Epoch -  5 Loss -  32.54252789451316\n",
      "Epoch -  6 Loss -  7.423857967781929\n",
      "Epoch -  7 Loss -  1.1909637332637406\n",
      "Epoch -  8 Loss -  0.9386138904535631\n",
      "Epoch -  9 Loss -  0.9308414897621045\n",
      "Epoch -  10 Loss -  0.9245212843522719\n",
      "Epoch -  11 Loss -  0.9182134935056728\n",
      "Epoch -  12 Loss -  0.9121627679367478\n",
      "Epoch -  13 Loss -  0.9063888824548739\n",
      "Epoch -  14 Loss -  0.9008818303671834\n",
      "Epoch -  15 Loss -  0.895628880249528\n",
      "Epoch -  16 Loss -  0.8906176333337836\n",
      "Epoch -  17 Loss -  0.8858363257828941\n",
      "Epoch -  18 Loss -  0.8812738240078257\n",
      "Epoch -  19 Loss -  0.8769195885332947\n",
      "Epoch -  20 Loss -  0.8727636370996154\n",
      "Epoch -  21 Loss -  0.8687965101937951\n",
      "Epoch -  22 Loss -  0.8650092391390014\n",
      "Epoch -  23 Loss -  0.8613933165507348\n",
      "Epoch -  24 Loss -  0.8579406689534024\n",
      "Epoch -  25 Loss -  0.8546436313679096\n",
      "Epoch -  26 Loss -  0.851494923699707\n",
      "Epoch -  27 Loss -  0.8484876287735277\n",
      "Epoch -  28 Loss -  0.8456151718762301\n",
      "Epoch -  29 Loss -  0.8428713016826173\n",
      "Epoch -  30 Loss -  0.840250072451113\n",
      "Epoch -  31 Loss -  0.8377458273869187\n",
      "Epoch -  32 Loss -  0.8353531830798999\n",
      "Epoch -  33 Loss -  0.8330670149330108\n",
      "Epoch -  34 Loss -  0.8308824435048313\n",
      "Epoch -  35 Loss -  0.8287948216966626\n",
      "Epoch -  36 Loss -  0.8267997227209152\n",
      "Epoch -  37 Loss -  0.8248929287930332\n",
      "Epoch -  38 Loss -  0.8230704204943521\n",
      "Epoch -  39 Loss -  0.8213283667577386\n",
      "Epoch -  40 Loss -  0.8196631154320103\n",
      "Epoch -  41 Loss -  0.8180711843848496\n",
      "Epoch -  42 Loss -  0.8165492531072669\n",
      "Epoch -  43 Loss -  0.8150941547856855\n",
      "Epoch -  44 Loss -  0.8137028688105052\n",
      "Epoch -  45 Loss -  0.8123725136925014\n",
      "Epoch -  46 Loss -  0.8111003403606387\n",
      "Epoch -  47 Loss -  0.8098837258169838\n",
      "Epoch -  48 Loss -  0.808720167126269\n",
      "Epoch -  49 Loss -  0.8076072757193268\n",
      "Epoch -  50 Loss -  0.8065427719912547\n",
      "Epoch -  51 Loss -  0.8055244801764662\n",
      "Epoch -  52 Loss -  0.804550323484223\n",
      "Epoch -  53 Loss -  0.8036183194793087\n",
      "Epoch -  54 Loss -  0.8027265756936484\n",
      "Epoch -  55 Loss -  0.8018732854556815\n",
      "Epoch -  56 Loss -  0.8010567239251651\n",
      "Epoch -  57 Loss -  0.800275244321939\n",
      "Epoch -  58 Loss -  0.7995272743379903\n",
      "Epoch -  59 Loss -  0.7988113127227754\n",
      "Epoch -  60 Loss -  0.7981259260325124\n",
      "Epoch -  61 Loss -  0.7974697455346632\n",
      "Epoch -  62 Loss -  0.7968414642594419\n",
      "Epoch -  63 Loss -  0.7962398341906555\n",
      "Epoch -  64 Loss -  0.7956636635887111\n",
      "Epoch -  65 Loss -  0.7951118144389531\n",
      "Epoch -  66 Loss -  0.7945832000190409\n",
      "Epoch -  67 Loss -  0.7940767825793443\n",
      "Epoch -  68 Loss -  0.79359157113071\n",
      "Epoch -  69 Loss -  0.7931266193343054\n",
      "Epoch -  70 Loss -  0.7926810234885153\n",
      "Epoch -  71 Loss -  0.7922539206081766\n",
      "Epoch -  72 Loss -  0.791844486591642\n",
      "Epoch -  73 Loss -  0.7914519344714883\n",
      "Epoch -  74 Loss -  0.7910755127448377\n",
      "Epoch -  75 Loss -  0.7907145037795382\n",
      "Epoch -  76 Loss -  0.7903682222925905\n",
      "Epoch -  77 Loss -  0.7900360138974312\n",
      "Epoch -  78 Loss -  0.7897172537168606\n",
      "Epoch -  79 Loss -  0.7894113450585376\n",
      "Epoch -  80 Loss -  0.7891177181501637\n",
      "Epoch -  81 Loss -  0.7888358289315738\n",
      "Epoch -  82 Loss -  0.7885651579011255\n",
      "Epoch -  83 Loss -  0.7883052090138977\n",
      "Epoch -  84 Loss -  0.7880555086293256\n",
      "Epoch -  85 Loss -  0.7878156045060243\n",
      "Epoch -  86 Loss -  0.7875850648416388\n",
      "Epoch -  87 Loss -  0.7873634773556913\n",
      "Epoch -  88 Loss -  0.7871504484134997\n",
      "Epoch -  89 Loss -  0.7869456021892514\n",
      "Epoch -  90 Loss -  0.7867485798665511\n",
      "Epoch -  91 Loss -  0.7865590388746746\n",
      "Epoch -  92 Loss -  0.7863766521589914\n",
      "Epoch -  93 Loss -  0.7862011074839812\n",
      "Epoch -  94 Loss -  0.7860321067674019\n",
      "Epoch -  95 Loss -  0.7858693654442057\n",
      "Epoch -  96 Loss -  0.7857126118588937\n",
      "Epoch -  97 Loss -  0.785561586685008\n",
      "Epoch -  98 Loss -  0.7854160423705745\n",
      "Epoch -  99 Loss -  0.7852757426083291\n",
      "Epoch -  100 Loss -  0.7851404618296364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.53040134,  0.30133401],\n",
       "        [-0.59081655, -0.36453137]]),\n",
       " 'b1': array([[ 0.08903173],\n",
       "        [-0.10242878]]),\n",
       " 'W2': array([[ 0.50713598, -0.57525164]]),\n",
       " 'b2': array([[0.46082716]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs implementation\n",
    "\n",
    "parameters = initialize_weights_and_bias([2,2,1])\n",
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  Loss = []\n",
    "\n",
    "  for j in range(df.shape[0]):\n",
    "\n",
    "    X = df[['CGPA', 'PROFILE_SCORE']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "    y = df[['LPA']].values[j][0]\n",
    "\n",
    "    # Parameter initialization\n",
    "\n",
    "\n",
    "    y_hat,A1 = L_layer_forward(X,parameters)\n",
    "    y_hat = y_hat[0][0]\n",
    "\n",
    "    update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "    Loss.append((y-y_hat)**2)\n",
    "\n",
    "  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())\n",
    "\n",
    "parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
